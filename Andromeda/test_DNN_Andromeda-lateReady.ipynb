{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andromeda in Jupyter\n",
    "\n",
    "### Interactive Inverse Dimension Reduction \n",
    "\n",
    "This notebook implements interactive dimension reduction (DR) for exploratory analysis of high-dimensional data.\n",
    "It uses a Multi-Dimensional Scaling (MDS) algorithm with a weighted distance metric. It enables both forward and inverse DR interaction. \n",
    "\n",
    "**MDS** projects high-dimensional data to a 2D scatterplot. A **weighted distance function** with user-specified weights on each dimension enables alternative projections that emphasize different dimensions. An **Inverse-DR** algorithm learns distance function weights for  user-constructed layouts of the data points.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Run All\n",
    "1. Proceed to the interactive plots near the bottom\n",
    "1. There are three kinds of interactions:\n",
    "    1. Select points in the DR plot and click Details to see data values.\n",
    "    1. **Parametric interaction:** Adjust the weight sliders and click Apply to alter the projection plot.\n",
    "    1. **Projection interaction:** Drag points in the projection plot, then click Learn to see learned weights, and click Copy to see the updated projection plot.\n",
    "1. Be patient, its interactive matplotlib in python and Jupyter!\n",
    "\n",
    "### Credits:\n",
    "\n",
    "Authors: Han Liu and Chris North, Dept of Computer Science, Virginia Tech.\n",
    "\n",
    "Based on: *Self JZ, Dowling M, Wenskovitch J, Crandell I, Wang M, House L, Leman S, North C. Observation-Level and Parametric Interaction for High-Dimensional Data Analysis. ACM Transactions on Interactive Intelligent Systems.  8(2), 2018.* https://infovis.cs.vt.edu/sites/default/files/observation-level-parametric_first_look_version.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# interactive notebook format is required for the interactive plot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "import sklearn.metrics.pairwise\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Pre-process Data\n",
    "\n",
    "Change the **filename** to load a dataset.  CSV data file is expected to have a first column 'Name' that is used as the index, and header row of column names.  Numeric columns are used for projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColorHist_Andromeda.ipynb          VGG_DNN_Andromeda.ipynb\r\n",
      "OppSift_Andromeda.ipynb            Version0720.ipynb\r\n",
      "ResNet_DNN_Andromeda.ipynb         test_DNN_Andromeda-disease.ipynb\r\n",
      "Sift_Andromeda.ipynb               test_DNN_Andromeda-lateReady.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../csvFiles/DNNFeaturesLayer2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5957a0ec75cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#filename = 'InfoVis_Fall_2015_Survey.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../csvFiles/DNNFeaturesLayer2.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# df['Image'] = df['Image'].apply(lambda x: x.split('_')[2]+ x.split('_')[-2]+x.split('_')[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../csvFiles/DNNFeaturesLayer2.csv'"
     ]
    }
   ],
   "source": [
    "# filename = 'Animal_Data_Andromeda.csv'\n",
    "#filename = 'InfoVis_Fall_2015_Survey.csv'\n",
    "filename = '../csvFiles/DNNFeaturesLayer2.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# df['Image'] = df['Image'].apply(lambda x: x.split('_')[2]+ x.split('_')[-2]+x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'Name' column as index\n",
    "#df.rename(columns={df.columns[0]:'Name'}, inplace=True)\n",
    "df.set_index('Image', inplace=True)\n",
    "\n",
    "# Sort rows and columns\n",
    "# df.sort_index(axis=1, inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "df_numeric = df.select_dtypes(include='number')  #'int32' or 'int64' or 'float32' or 'float64'\n",
    "df_category = df.select_dtypes(exclude='number') #'object'\n",
    "\n",
    "# Z-score normalization\n",
    "# normalized_df = (df_numeric - df_numeric.mean()) / df_numeric.std()\n",
    "normalized_df = df_numeric  # do not normalize animal dataset, all columns are 0-100 scale\n",
    "\n",
    "print('Data size (r,c) =', df_numeric.shape)\n",
    "df_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dimension Reduction Model:  Weighted MDS\n",
    "\n",
    "For DR, we use the Multi-Dimensional Scaling (MDS) algorithm on a weighted data space. **Dimension weights** are applied to the high-dimensional (HD) data.  Weights are normalized to sum to 1, so as to normalize the HD distances to roughly constant size space independent of p.\n",
    "\n",
    "The **distance function for the high-dimensional (HD) data** is L1 manhattan distance. L1 is good for general purpose use with multi-dimensional quantitative datasets. \n",
    "\n",
    "The **distance function for the 2D projected points** is L2 Euclidean distance, which makes sense for human percpetion in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distance matrix for the weighted high-dimensional data using L1 distance function.\n",
    "#  Input HD data should already be weighted.\n",
    "def distance_matrix_HD(dataHDw):  # dataHDw (pandas or numpy) -> distance matrix (numpy)\n",
    "    dist_matrix = sklearn.metrics.pairwise.manhattan_distances(dataHDw)\n",
    "    #m = pd.DataFrame(m, columns=dataHD.index, index=dataHD.index)  # keep as np array for performance\n",
    "    return dist_matrix\n",
    "\n",
    "# Compute the distance matrix for 2D projected data using L2 distance function.\n",
    "def distance_matrix_2D(data2D):  # data2d (pandas or numpy) -> distance matrix (numpy)\n",
    "    dist_matrix = sklearn.metrics.pairwise.euclidean_distances(data2D) \n",
    "    #m = pd.DataFrame(m, columns=data2D.index, index=data2D.index) # keep as np array for performance\n",
    "    return dist_matrix\n",
    "\n",
    "#def dist(x,y):\n",
    "#    return np.linalg.norm(x-y, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDS** projects the weighted high-dimensional data to 2D. Tune the algorithm's parameters for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MDS stress metric between HD and 2D distances.  Uses numpy for efficiency.\n",
    "def stress(distHD, dist2D):  #  distHD, dist2D (numpy) -> stress (float)\n",
    "    #s = np.sqrt((distHD-dist2D).pow(2).sum().sum() / distHD.pow(2).sum().sum())  # pandas\n",
    "    #s = np.sqrt(((distHD-dist2D)**2).sum() / (distHD**2).sum())   # numpy\n",
    "    s = ((distHD-dist2D)**2).sum() / (distHD**2).sum()   # numpy, eliminate sqrt for efficiency\n",
    "    return s\n",
    "\n",
    "def compute_mds(dataHDw):  # dataHDw -> data2D (pandas)\n",
    "    distHD = distance_matrix_HD(dataHDw)\n",
    "    # Adjust these parameters for performance/accuracy tradeoff\n",
    "    mds = sklearn.manifold.MDS(n_components=2, dissimilarity='precomputed', n_init=10, max_iter=1000)\n",
    "    # Reduction algorithm happens here:  data2D is nx2 matrix\n",
    "    data2D = mds.fit_transform(distHD)\n",
    "    \n",
    "    # Rotate the resulting 2D projection to make it more consistent across multiple runs.\n",
    "    # Set the 1st PC to the y axis, plot looks better to spread data vertically with horizontal text labels\n",
    "    pca = sklearn.decomposition.PCA(n_components=2)\n",
    "    data2D = pca.fit_transform(data2D)\n",
    "    data2D = pd.DataFrame(data2D, columns=['y','x'], index=dataHDw.index)\n",
    "    \n",
    "    data2D.stress_value = stress(distHD, distance_matrix_2D(data2D))\n",
    "    return data2D\n",
    "\n",
    "def dimension_reduction(dataHD, wts): # dataHD, wts -> data2D (pandas)\n",
    "    # Normalize the weights to sum to 1\n",
    "    wts = wts/wts.sum()\n",
    "    \n",
    "    # Apply weights to the HD data \n",
    "    dataHDw = dataHD * wts\n",
    "    \n",
    "    # DR algorithm\n",
    "    data2D = compute_mds(dataHDw)\n",
    "\n",
    "    # Compute row relevances as:  data dot weights\n",
    "    # High relevance means large values in upweighted dimensions\n",
    "    data2D['relevance'] = dataHDw.sum(axis=1)\n",
    "    return data2D\n",
    "\n",
    "\n",
    "min_weight, max_weight = 0.00001, 0.9999\n",
    "init_weight = min_weight  # 1.0/len(normalized_df.columns) # initialize to min to make the sliders easier to use.\n",
    "weights = pd.Series(init_weight, index=normalized_df.columns, name=\"Weight\")  # the current weight list\n",
    "\n",
    "df_2D = dimension_reduction(normalized_df, weights)   # the current projected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(distance_matrix_HD(normalized_df * (weights/weights.sum())), \n",
    "             columns=normalized_df.index, index=normalized_df.index).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2D.stress_value)\n",
    "df_2D.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Dimension-Reduction Learning Algorithm\n",
    "\n",
    "Computes the inverse-Dimension-Reduction: given input 2D points, compute new weights.\n",
    "Optimizes the MDS stress function that compares 2D pairwise distances (||$x_i-x_j||$) to weighted HD pairwise distances ($d_{ij}$):\n",
    "![Stress](https://wikimedia.org/api/rest_v1/media/math/render/svg/7989b3afc0d8795a78c1631c7e807f260d9cfe68)\n",
    "\n",
    "Technically, we compute the inverse weighted distance function. We shortcut the optimization by eliminating MDS from the process, and assume that the user input 2D distances are actually the desired HD distances, not the 2D distances after re-projection. Thus, given the input (HD) distances, we find weights that would produce these distances in the HD space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is used to propose a new weight for current column in a smart fashion\n",
    "def new_proposal(current, step, direction):\n",
    "    return np.clip(current + direction*step*random.random(), 0.00001, 0.9999)\n",
    "\n",
    "# Repeatedly tries to modify each dim weight to see if it improves the stress, thus\n",
    "# getting the weighted high-dim distances to more closely match the input 2D distances.\n",
    "#   dataHD = high-dim data, as pandas\n",
    "#   data2D = 2D data input, as pandas\n",
    "#   weights = as pandas series, or None for weights[i]=1/p\n",
    "def inverse_DR(dataHD, data2D, curWeights=None):  # -> new weights, as Series\n",
    "    dist2D = distance_matrix_2D(data2D)  # compute 2D distances only once\n",
    "    col_names = dataHD.columns\n",
    "    dataHD = dataHD.to_numpy()  # use numpy for efficiency\n",
    "    row, col = dataHD.shape\n",
    "    \n",
    "    if curWeights==None:\n",
    "        curWeights = np.array([1.0/col]*col)  # default weights = 1/p\n",
    "    else:\n",
    "        curWeights = curWeights.to_numpy()\n",
    "        curWeights = curWeights / curWeights.sum()  # Normalize weights to sum to 1\n",
    "    newWeights = curWeights.copy()  # re-use this array for efficiency\n",
    "    \n",
    "    # Initialize state\n",
    "    flag = [0]*col         # degree of success of a weight change\n",
    "    direction = [1]*col  # direction to move a weight, pos or neg\n",
    "    step = [1.0/col]*col   # how much to change each weight\n",
    "    \n",
    "    dataHDw = dataHD * curWeights   # weighted space, re-use this array for efficiency\n",
    "    distHD = distance_matrix_HD(dataHDw)\n",
    "    curStress = stress(distHD, dist2D)\n",
    "    print('Starting stress =', curStress, 'Processing...')\n",
    "\n",
    "    MAX = 500   # default setting of the number of iterations\n",
    "\n",
    "    # Try to minorly adjust each weight to see if it reduces stress\n",
    "    for i in range(MAX):\n",
    "        for dim in range(col):            \n",
    "            # Get a new weight for current column\n",
    "            nw = new_proposal(curWeights[dim], step[dim], direction[dim])\n",
    "            \n",
    "            # Scale the weight list such that it sums to 1\n",
    "            #newWeights = curWeights.copy()  # avoid extra copy op using math below\n",
    "            #newWeights[dim] = nw\n",
    "            #newWeights = newWeights / s\n",
    "            s = 1.0  + nw - curWeights[dim]   # 1.0 == curWeights.sum()\n",
    "            np.true_divide(curWeights, s, out=newWeights)  # transfers to other array, while doing /\n",
    "            newWeights[dim] = nw / s\n",
    "            \n",
    "            # Apply new weights to HD data\n",
    "            np.multiply(dataHD, newWeights, out=dataHDw)  # dataHDw = dataHD * newWeights; efficiently reuses dataHDw array\n",
    "            distHD = distance_matrix_HD(dataHDw)\n",
    "\n",
    "            # Get the new stress\n",
    "            newStress = stress(distHD, dist2D)\n",
    "            \n",
    "            # If new stress is lower, then update weights and flag this success\n",
    "            if newStress < curStress:\n",
    "                temp = curWeights\n",
    "                curWeights = newWeights\n",
    "                newWeights = temp   # reuse the old array next iteration\n",
    "                curStress = newStress\n",
    "                flag[dim] = flag[dim] + 1\n",
    "            else:\n",
    "                flag[dim] = flag[dim] - 1\n",
    "                direction[dim] = -direction[dim]  # Reverse course\n",
    "    \n",
    "            # If recent success, then speed up the step rate\n",
    "            if flag[dim] >= 5:\n",
    "                step[dim] = step[dim] * 2\n",
    "                flag[dim] = 0\n",
    "            elif flag[dim] <= -5:\n",
    "                step[dim] = step[dim] / 2\n",
    "                flag[dim] = 0\n",
    "                \n",
    "    print('Solution stress =', curStress, 'Done.')\n",
    "    #print(\"weight\", curWeights)\n",
    "    #print(\"flag\", flag)\n",
    "    #print(\"dir\", direction)\n",
    "    #print(\"step\", step)\n",
    "    return pd.Series(curWeights, index=col_names, name=\"Weight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and UI code\n",
    "\n",
    "Use these functions to create the GUI components in any cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliders(wts):\n",
    "    # Create sliders, one for each dimension weight\n",
    "    sliders = [widgets.FloatSlider(min=min_weight, max=max_weight, step=0.01, value=value, \n",
    "                                       description=label, continuous_update=False, readout_format='.5f')\n",
    "                   for (label, value) in wts.iteritems()]\n",
    "    # Display sliders\n",
    "    for s in sliders:\n",
    "        #s.observe(sliderchange, names='value')\n",
    "        display(s)\n",
    "        \n",
    "    create_slider_buttons(sliders)\n",
    "    return sliders\n",
    "\n",
    "def create_slider_buttons(sliders):    \n",
    "    apply_button = widgets.Button(description='Apply Slider Weights')\n",
    "    reset_button = widgets.Button(description='Reset Plot')\n",
    "\n",
    "    # Callback functions\n",
    "    def apply_button_clicked(change):\n",
    "        # Use the slider values to re compute the DR and redraw the plot\n",
    "        global weights, df_2D   # Update weights and df_2D globals\n",
    "        weights = pd.Series([s.value for s in sliders], index=normalized_df.columns, name='Weight')\n",
    "        df_2D = dimension_reduction(normalized_df, weights)   \n",
    "        \n",
    "        # Re-draw the plot\n",
    "        draw_plot(plot_ax, df_2D)\n",
    "    apply_button.on_click(apply_button_clicked)\n",
    "\n",
    "    def reset_button_clicked(change):\n",
    "        # Reset all sliders to initial value and re-compute DR and re-draw the plot\n",
    "        for s in sliders:\n",
    "            s.value = init_weight\n",
    "        apply_button_clicked(change)\n",
    "    reset_button.on_click(reset_button_clicked)\n",
    "    \n",
    "    # Display buttons\n",
    "    display(apply_button)\n",
    "    display(reset_button)\n",
    "    return apply_button, reset_button\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Details Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detail_display():\n",
    "    # Print selected points\n",
    "    print_button = widgets.Button(description='Print selected points')\n",
    "    print_output = widgets.Output()\n",
    "\n",
    "    def print_button_clicked(change):\n",
    "        print_output.clear_output()\n",
    "        # Get list of selected points and print their source data values\n",
    "        selset = [c.index for c in plot_ax.circles if c.selected]\n",
    "        with print_output:\n",
    "            if len(selset) > 0:\n",
    "                print(df.iloc[selset, :].transpose())\n",
    "            else:\n",
    "                print('Select points in the plot to see details here')\n",
    "    print_button.on_click(print_button_clicked)\n",
    "\n",
    "    display(print_button)\n",
    "    display(print_output)\n",
    "    return print_button, print_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse DR Button and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverse_button():\n",
    "    inverse_button = widgets.Button(description='Learn New Weights')\n",
    "    copy_button = widgets.Button(description='Copy to Sliders')\n",
    "\n",
    "    def inverse_button_clicked(change):\n",
    "        ax.clear()\n",
    "\n",
    "        # Check minimum number of points moved\n",
    "        n = len([1 for c in plot_ax.circles if c.selected])\n",
    "        if n < 2:\n",
    "            print('Need to select or move at least 2 points in the plot first.')\n",
    "            return\n",
    "\n",
    "        # Get selected data points\n",
    "        data2Dnew = pd.DataFrame([c.center for c in plot_ax.circles if c.selected], columns=['x','y'], \n",
    "                                index=[c.label for c in plot_ax.circles if c.selected])\n",
    "        dataHDpart = normalized_df.loc[data2Dnew.index]\n",
    "\n",
    "        # Learn new weights\n",
    "        global weights\n",
    "        weights = inverse_DR(dataHDpart, data2Dnew)\n",
    "        \n",
    "        # Display new weights as a bar chart\n",
    "        weights.sort_index(ascending=False).plot.barh(ax=ax)\n",
    "        ax.set_xlabel(\"Weight\")\n",
    "        fig.tight_layout()\n",
    "    inverse_button.on_click(inverse_button_clicked)\n",
    "\n",
    "    def copy_button_clicked(change):\n",
    "        # Set sliders to reflect the learned weights and update the DR and plot accordingly\n",
    "        global df_2D\n",
    "        for i,s in enumerate(sliders):\n",
    "            s.value = weights[i]\n",
    "        df_2D = dimension_reduction(normalized_df, weights)   \n",
    "        draw_plot(plot_ax, df_2D)\n",
    "    copy_button.on_click(copy_button_clicked)\n",
    "    display(inverse_button)\n",
    "    display(copy_button)\n",
    "    fig, ax = plt.subplots(figsize=(5,7))   # reserve a fig for the weights bar chart\n",
    "    return inverse_button, copy_button, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draggable Dimension-Reduction 2D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles mouse drag interaction events in the plot, users can select and drag points.\n",
    "class DraggablePoints(object):\n",
    "    def __init__(self, ax, artists):\n",
    "        self.ax = ax\n",
    "        self.artists = artists\n",
    "        self.current_artist = None\n",
    "        self.last_selected = None\n",
    "        ax.selected_text.set_text('Selected: none')\n",
    "        self.offset = (0, 0)\n",
    "        # Set up mouse listeners\n",
    "        ax.figure.canvas.mpl_connect('pick_event', self.on_pick)\n",
    "        ax.figure.canvas.mpl_connect('motion_notify_event', self.on_motion)\n",
    "        ax.figure.canvas.mpl_connect('button_release_event', self.on_release)\n",
    "\n",
    "    def on_pick(self, event):\n",
    "        # When point is clicked on (mouse down), select it and start the drag\n",
    "        if self.current_artist is None:  # clicking on overlapped points sends multiple events\n",
    "            self.last_selected = event.artist.index  # event.ind\n",
    "            self.current_artist = event.artist\n",
    "            event.artist.selected = True\n",
    "            event.artist.savecolor = event.artist.get_facecolor()\n",
    "            event.artist.set_facecolor('green')\n",
    "            #event.artist.set_alpha(1.0)\n",
    "            self.ax.selected_text.set_text(\"Selected: \" + event.artist.label)\n",
    "            x0, y0 = event.artist.center\n",
    "            self.offset = (x0 - event.mouseevent.xdata), (y0 - event.mouseevent.ydata)\n",
    "\n",
    "    def on_motion(self, event):\n",
    "        # When dragging, check if point is selected and valid mouse coordinates\n",
    "        if (self.current_artist is not None) and (event.xdata is not None) and (event.ydata is not None):\n",
    "            # Drag the point and its text label\n",
    "            dx, dy = self.offset\n",
    "            self.current_artist.center = x0, y0 = event.xdata + dx, event.ydata + dy\n",
    "            self.current_artist.text.set_position((x0 - self.current_artist.radius/2, \n",
    "                                                   y0 - self.current_artist.radius/2))\n",
    "            #self.ax.figure.canvas.draw()  # slow\n",
    "        \n",
    "    def on_release(self, event):\n",
    "        # When mouse is released, stop the drag\n",
    "        self.current_artist = None\n",
    "        #self.ax.figure.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_plot(data2D):\n",
    "    # Initialize DR plot figure\n",
    "    fig, ax = plt.subplots(figsize= (8,7))\n",
    "    ax.selected_text = ax.figure.text(0,0.005, 'Selected: none', wrap=True, color='green')\n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=matplotlib.colors.Normalize(), cmap=plt.cm.plasma), ax=ax, label=\"Relevance\", ticks=[], shrink=0.5, aspect=40, fraction=0.05)\n",
    "    # ax = data2D.plot.scatter(x=\"x\", y=\"y\", alpha=0.5, c=\"relevance\", s=75, ax=ax\n",
    "    #                   colormap=plt.cm.plasma, sharex=False, figsize=(8, 6), picker=True)\n",
    "    # ax.collections[0].get_offsets());   set_offsets(data2D[['y','x']]);   .get_facecolors()\n",
    "    \n",
    "    # Clean up the plot\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.figure.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    # Store state data:\n",
    "    ax.circles = None\n",
    "    ax.dragpoint = None\n",
    "    \n",
    "    draw_plot(ax, data2D)\n",
    "    return ax\n",
    "\n",
    "def draw_plot(ax, data2D):\n",
    "    # Re-draws the DR plot in the axes with the updated data2D\n",
    "    ax.clear()\n",
    "    # Map data to circles, with x, y, and relevance->color\n",
    "    wid = max(data2D.x.max() - data2D.x.min(), data2D.y.max() - data2D.y.min())  # max range of x,y axes\n",
    "    cnorm = matplotlib.colors.Normalize(vmin=data2D.relevance.min(), vmax=data2D.relevance.max())\n",
    "    ax.circles = data2D.apply(axis=1, func=lambda row: \n",
    "        matplotlib.patches.Circle(xy=(row.x, row.y), radius=wid/70, alpha=0.5, \n",
    "                                  color=plt.cm.plasma(cnorm(row.relevance)), picker=True))\n",
    "    for i,c in enumerate(ax.circles):\n",
    "        # Store state data:\n",
    "        c.index, c.label, c.selected = i, data2D.index[i], False\n",
    "        # Draw circles and text labels in plot\n",
    "        ax.add_patch(c)\n",
    "        c.text = ax.text(c.center[0]-c.radius/2, c.center[1]-c.radius/2, c.label)\n",
    "    # Make plot circles draggable\n",
    "    ax.dragpoint = DraggablePoints(ax, ax.circles)\n",
    "    \n",
    "    # Clean up the plot\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('equal')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliders\n",
    "Use the sliders to control the **dimension weights** for the input HD data. The weights indicate which dimensions are given more emphasis in the DR plot distances.  For computational reasons, weights cannot go to absolute zero. When used in DR, the weights are first normalized such that they sum to 1.\n",
    "\n",
    "After adjusting the sliders, click the **Apply** button to show the results in the DR plot.\n",
    "\n",
    "To reset the sliders to their default values, click the **Reset** button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sliders = create_sliders(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction Plot\n",
    "This shows the HD data in 2D form, such that **proximity == similarity**, based on the current slider weights.  Distances between points in the plot approximately reflect their distances in the weighted HD data.  Thus points near each other have similar HD data values in the up-weighted dimensions, and points far away have very different HD data values in those dimensions.\n",
    "\n",
    "The color represents the **relevance** of each point to the current slider weights. Yellower points have larger values in up-weighted dimensions.\n",
    "\n",
    "Points can be **selected** to highlight in Green and view their details below.  Points can be **dragged** to specify a new projection for learning weights, see below. To reset the plot and clear the selections, click the **Reset** button above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ax = create_plot(df_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Selected Points Details\n",
    "Click the **Print** button below to display detailed data values of the points selected in the DR plot.  The selected points are Green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dod = create_detail_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Dimension Reduction\n",
    "After selecting and/or dragging some points in the DR plot, click the **Learn** button to machine learn new dimension weights that would produce a plot with similar pairwise distances as your plot.  **Only the Green selected points** in the plot are considered when learning new weights. You must select or move at least two points to specify new desired distances. Use this to create your own clusters, and find out what makes some data points similar to or different from others.  The **learned weights** are shown in a bar chart below.\n",
    "\n",
    "To see the effects of the learned weights, click the **Copy** button to apply the learned weights to the sliders and  make a new DR plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inverse = create_inverse_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ./testTrainingData/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
